{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sauce=uReq(\"https://pythonprogramming.net/parsememcparseface/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= BeautifulSoup(sauce,\"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# soup.title\n",
    "soup.title.text\n",
    "soup.title.string#children vaya none niskinxa "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soup.find_all(\"p\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for para in soup.findAll(\"p\"):\n",
    "    print(\"$\",para.string)\n",
    "#     print(\"-\"*20)\n",
    "    print(para.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soup.getText().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in soup.findAll(\"a\"):\n",
    "    print(url)\n",
    "    #print(url.text)#yesla tyo tag bhitra ko text lai print hanxa aba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  FOR GETTING STRING BETN TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in soup.findAll(\"a\"):\n",
    "#     print(url)\n",
    "    print(url.text)#yesla tyo tag bhitra ko text lai print hanxa aba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR LINKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in soup.findAll(\"a\"):\n",
    "    print(url.get(\"href\"))#we have the links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR SPECIFIC SET OF URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav=soup.nav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in nav.findAll(\"a\"):\n",
    "    print(\"url:\",url.get(\"href\"))\n",
    "    #double kina axa vanda tesma deuta nav bar xa auta mobile ko lai ra normal ko lai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "body=soup.body\n",
    "for para in body.findAll(\"p\"):\n",
    "    print(para.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for div in soup.findAll(\"div\",class_=\"body\"):\n",
    "    print(div.text)#we get all the div text #without class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  SCRAPING FROM TABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SELF WAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from urllib.request import urlopen as uReq\n",
    "\n",
    "sauce=uReq(\"https://pythonprogramming.net/parsememcparseface/\")\n",
    "\n",
    "soup = BeautifulSoup(sauce,\"lxml\")\n",
    "\n",
    "table=soup.table\n",
    "\n",
    "table_row=table.findAll(\"tr\")[1:]\n",
    "\n",
    "table_row[0].findAll(\"td\")\n",
    "\n",
    "for i in table_row:\n",
    "#     print(i)\n",
    "    for j in i.findAll(\"td\"):\n",
    "        print(j.text,end=\" \")\n",
    "    print(\"BREAK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  EXPERT WAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from urllib.request import urlopen as uReq\n",
    "\n",
    "sauce=uReq(\"https://pythonprogramming.net/parsememcparseface/\").read()\n",
    "\n",
    "soup = BeautifulSoup(sauce,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=soup.find(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_row=table.findAll(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr in table_row:\n",
    "    td=tr.findAll(\"td\")\n",
    "    row=[i.text for i in td]#.text ka bhitra ko text dinxa\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE PANDAS WAY MORE  BETTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install Pandas#its a data analysis library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs = pd.read_html(\"https://pythonprogramming.net/parsememcparseface/\")\n",
    "#its gonna go to the website its gonna parse all the table it can find and return a list of data frames\n",
    "\n",
    "\n",
    "dfs = pd.read_html(\"https://pythonprogramming.net/parsememcparseface/\",header=0)#its will make the first row as header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:#df means dataframe meaning table 0\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sitemap -maps of all the urls in our website\n",
    "#### it will have all the links including new ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sauce=uReq(\"https://pythonprogramming.net/sitemap.xml\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(sauce,\"xml\")\n",
    "#links are in loc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in soup.findAll(\"loc\"):\n",
    "    print(url.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DYNAMIC JAVASCRIPT SCRAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how to scrap dynamically updated information from a webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen as uReq\n",
    "\n",
    "sauce=uReq(\"https://pythonprogramming.net/parsememcparseface\n",
    "\n",
    "soup=BeautifulSoup(sauce,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_test=soup.find(\"p\",class_=\"jstest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"jstest\" id=\"yesnojs\">y u bad tho?</p>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js_test#we arent a browser so we get other result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now we must act as a browser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys#qt application needs system argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import QApplication\n",
    "#Qapplication its a thing for making application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtCore import QUrl\n",
    "#read the url this is how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWebEngineWidgets import QWebEnginePage#QWebPage\n",
    "#load the page and act as a browser ,act like a client and run that java script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client(QWebEnginePage):\n",
    "    def __init__(self, url):\n",
    "        self.app=QApplication(sys.argv)#initializing the application\n",
    "        QWebEnginePage.__init__(self)#initializing QWenapge\n",
    "        self.html=\"\"\n",
    "        self.loadFinished.connect(self.on_page_load)#connecting the method when the load is finished\n",
    "        self.load(QUrl(url))\n",
    "        self.app.exec_()\n",
    "        \n",
    "        \n",
    "    def on_page_load(self):\n",
    "        self.html = self.toHtml(self.Callable)\n",
    "#         self.app.quit()\n",
    "        \n",
    "    def Callable(self, html_str):\n",
    "        self.html = html_str\n",
    "        self.app.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://pythonprogramming.net/parsememcparseface/\"\n",
    "\n",
    "client_response=Client(url)\n",
    "\n",
    "source=client_response.mainFrame().toHtml()\n",
    "#QWebEngneView object lets get the mainFrame the one we looking at conver it into html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look at you shinin!\n"
     ]
    }
   ],
   "source": [
    "page = Client('https://pythonprogramming.net/parsememcparseface/')\n",
    "soup = BeautifulSoup(page.html, 'html.parser')\n",
    "js_test = soup.find('p', class_='jstest')\n",
    "print(js_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
